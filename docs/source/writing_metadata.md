# Developing Metadata

All AIND data assets must include rich metadata. The purpose of these files is to provide complete experimental details and documentation so that all users have a thorough understanding of the data.

You can learn about the metadata itself in the [aind-data-schema docs](https://aind-data-schema.readthedocs.io/en/latest/). This page is focused on helping you *develop* your metadata.

A lot of the metadata is automatically generated by the `data-transfer-service` when data is uploaded. For most users, the main pieces of metadata you are responsible for are the `rig/instrument`, `session`, `processing`, `procedures` outside of NSB, and `quality_control`. The `subject`, `data_description`, `session/acquisition`, and `procedures` from NSB can be populated automatically. For full details, see the [metadata services](metadata_services) page.

## Core Schema

### Rig / Instrument

The `rig.json` or `instrument.json` describe the hardware and software used to collect a data asset. 

### Session / Acquisition

Every data asset has a unique `session.json` or `acquisition.json` file that specifies the hardware, hardware-specific parameters (e.g. laser power), and stimuli parameters that were used during data collection. 

`session.json` is used for physiology and behavior data.  
`acquisition.json` is used for light sheet imaging. 

### Processing

The `processing.json` file keeps a record of the data processing and analysis steps applied to the original data asset. 

### Quality Control

Generating the `quality_control.json` file allows you to take advantage of the [QC Portal](https://qc.allenneuraldynamics.org/qc_portal_app), a SCICOMP maintained tool for querying and annotating data quality during processing and analysis.

The `quality_control.json` file should be generated or appended to at three times in a data asset's life: (1: Raw) immediately after data acquisition, (2: Processing) during processing when quality control metrics are computed, and (3: Analysis) during data analysis if further quality control is needed, for example for multi-asset quality metrics.

Detailed documentation for the QC metadata is found in the [aind-data-schema QC docs](https://aind-data-schema.readthedocs.io/en/latest/quality_control.html), while a walkthrough for AIND users can be found in the [QC portal docs](https://github.com/AllenNeuralDynamics/aind-qc-portal?tab=readme-ov-file#qc-portal)

## AIND Extensions

[coming soon]

## Valid vs Invalid Metadata

The metadata _schema_ defines the fields and types of data in each field that are expected for the different metadata files. We currently allow users to upload _invalid_ metadata because we are prioritizing data collection over perfect metadata, for now. In the future, the value of data is going to be measured not just by its quality but by its usefulness--and metadata is what makes your data re-usable.

You can check whether the metadata for an existing data asset is _valid_ using the [Metadata Portal](https://metadata-portal.allenneuraldynamics.org/). Each error thrown by the validator represents one field in your metadata that is either missing, has the wrong type of data, or is corrupt in some way. We are invested in complete and valid metadata -- reach out to scientific computing for help improving your metadata collection and back-filling metadata that is missing!
